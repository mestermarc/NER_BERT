{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "39aRqI0mofSZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch \n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.optim import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Word</th>\n",
              "      <th>POST</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 9001</td>\n",
              "      <td>In</td>\n",
              "      <td>IN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2005</td>\n",
              "      <td>CD</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Zambia</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>qualified</td>\n",
              "      <td>VBD</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentences       Word POST  Predicted\n",
              "0  Sentence: 9001         In   IN        NaN\n",
              "1             NaN       2005   CD        NaN\n",
              "2             NaN          ,    ,        NaN\n",
              "3             NaN     Zambia  NNP        NaN\n",
              "4             NaN  qualified  VBD        NaN"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FILEPATH = '../data/Test1NER.csv'\n",
        "header_names = ['Sentences', 'Word', 'POST', 'Predicted']\n",
        "test1_df = pd.read_csv(FILEPATH, sep=';', encoding= 'unicode_escape', names=header_names)\n",
        "test1_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19402"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test1_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_clean_word(inword):\n",
        "  if len(str(inword)) > 1:\n",
        "    stri = re.sub(\".|-|'\", '', str(inword))\n",
        "  else:\n",
        "    stri = re.sub(\"\\b-|'\\b\", '', str(inword))\n",
        "  return stri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_clean_word2(inword):\n",
        "  if len(str(inword)) > 1:\n",
        "    stri = re.sub(\"-|'\", '', str(inword))\n",
        "    stri = stri.replace('.', '')\n",
        "  else:\n",
        "    stri = re.sub(\"-|'\", '', str(inword))\n",
        "  return stri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len of sentences:900\n",
            "An example is:\n",
            " ['A', 'US', 'Energy', 'Department', 'report', 'Wednesday', 'says', 'the', 'amount', 'of', 'oil', 'available', 'in', 'the', 'United', 'States', 'declined', 'slightly', 'last', 'week', 'by', 'a', 'bit', 'more', 'than', 'one', 'million', 'barrels', ',', 'to', 'a', 'total', 'of', 'nearly', '314', 'million', 'barrels', '.']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "words = test1_df['Word'].values\n",
        "\n",
        "sentence_column = test1_df['Sentences'].values\n",
        "sentence_column = [str(cell) for cell in sentence_column]\n",
        "\n",
        "sentences = []\n",
        "sentence_tags = []\n",
        "\n",
        "for i in range(len(sentence_column)):\n",
        "    if sentence_column[i] != 'nan':\n",
        "        if i != 0 :sentences.append(sentence)\n",
        "        sentence = []\n",
        "        sentence.append(get_clean_word2(words[i]))\n",
        "    else:\n",
        "        sentence.append(get_clean_word2(words[i]))\n",
        "sentences.append(sentence)\n",
        "print(f'len of sentences:{(len(sentences))}')\n",
        "print('An example is:\\n', sentences[54])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len of sentences:900\n",
            "An example is:\n",
            " ['In', '2005', ',', 'Zambia', 'qualified', 'for', 'debt', 'relief', 'under', 'the', 'Highly', 'Indebted', 'Poor', 'Country', 'Initiative', ',', 'consisting', 'of', 'approximately', 'USD', '6', 'billion', 'in', 'debt', 'relief', '.']\n"
          ]
        }
      ],
      "source": [
        "words = test1_df['Word'].values\n",
        "\n",
        "sentence_column = test1_df['Sentences'].values\n",
        "sentence_column = [str(cell) for cell in sentence_column]\n",
        "\n",
        "sentences = []\n",
        "sentence_tags = []\n",
        "\n",
        "for i in range(len(sentence_column)):\n",
        "    if sentence_column[i] != 'nan':\n",
        "        if i != 0 :sentences.append(sentence)\n",
        "        sentence = []\n",
        "        sentence.append(str(words[i]))\n",
        "    else:\n",
        "        sentence.append(str(words[i]))\n",
        "sentences.append(sentence)\n",
        "print(f'len of sentences:{(len(sentences))}')\n",
        "print('An example is:\\n', sentences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An example is:\n",
            " I was arrested for striking a happy medium ...\n"
          ]
        }
      ],
      "source": [
        "list_of_string_sentences = [[' '.join(sentence)] for sentence in sentences]\n",
        "list_of_string_sentences = [item for sublist in list_of_string_sentences for item in sublist]\n",
        "print('An example is:\\n', list_of_string_sentences[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B6ISi50Moi5i",
        "outputId": "802e89bd-9fb2-4fcb-adfa-5a971190e803"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iranian officials say they expect to get acces...</td>\n",
              "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
              "      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>They left after a tense hour-long standoff wit...</td>\n",
              "      <td>O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n",
              "      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  Thousands of demonstrators have marched throug...   \n",
              "1  Iranian officials say they expect to get acces...   \n",
              "2  Helicopter gunships Saturday pounded militant ...   \n",
              "3  They left after a tense hour-long standoff wit...   \n",
              "4  U.N. relief coordinator Jan Egeland said Sunda...   \n",
              "\n",
              "                                              labels  \n",
              "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n",
              "1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n",
              "2  O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n",
              "3                              O O O O O O O O O O O  \n",
              "4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = pd.read_csv('../data/myNER.csv')\n",
        "df2 = pd.read_csv('../data/ner.csv')\n",
        "df = pd.concat([df2, df1], axis=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sOK050W2o9Mi"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2-1QW84spECY"
      },
      "outputs": [],
      "source": [
        "label_all_tokens = False\n",
        "\n",
        "def align_label(texts, labels):\n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "class DataSequence(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        lb = [i.split() for i in df['labels'].values.tolist()]\n",
        "        txt = df['text'].values.tolist()\n",
        "        self.texts = [tokenizer(str(i),\n",
        "                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n",
        "        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_data(self, idx):\n",
        "\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "\n",
        "        return torch.LongTensor(self.labels[idx])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_data = self.get_batch_data(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3mRm_oqepJnV"
      },
      "outputs": [],
      "source": [
        "#df = df[0:1000]\n",
        "\n",
        "labels = [i.split() for i in df['labels'].values.tolist()]\n",
        "unique_labels = set()\n",
        "\n",
        "for lb in labels:\n",
        "        [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
        "labels_to_ids = {k: v for v, k in enumerate(unique_labels)}\n",
        "ids_to_labels = {v: k for v, k in enumerate(unique_labels)}\n",
        "\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                            [int(.8 * len(df)), int(.9 * len(df))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdjxWDU8pPKS",
        "outputId": "9f871205-82bb-415b-8ffc-e7e2ff934642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45567"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G7jciOfNpiRX"
      },
      "outputs": [],
      "source": [
        "class BertModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertModel, self).__init__()\n",
        "\n",
        "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n",
        "\n",
        "    def forward(self, input_id, mask, label):\n",
        "\n",
        "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def align_word_ids(texts):\n",
        "  \n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(1)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(1 if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "\n",
        "def evaluate_one_text(model, sentence):\n",
        "\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    mask = text['attention_mask'].to(device)\n",
        "    input_id = text['input_ids'].to(device)\n",
        "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(input_id, mask, None)\n",
        "    logits_clean = logits[0][label_ids != -100]\n",
        "\n",
        "    predictions = logits_clean.argmax(dim=1).tolist()\n",
        "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
        "    return prediction_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "ename": "HFValidationError",
          "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/tokenizer/'. Use `repo_type` argument if needed.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32me:\\Projektek\\NER_BERT\\prev_notebooks\\predict_NER.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projektek/NER_BERT/prev_notebooks/predict_NER.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m MODELPATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../model/bertmodel.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projektek/NER_BERT/prev_notebooks/predict_NER.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_cuda \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projektek/NER_BERT/prev_notebooks/predict_NER.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizerFast\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m./models/tokenizer/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projektek/NER_BERT/prev_notebooks/predict_NER.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model2 \u001b[39m=\u001b[39m BertModel()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Projektek/NER_BERT/prev_notebooks/predict_NER.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model2\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(MODELPATH, map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(device)))\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1699\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtokenizer_file\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m vocab_files:\n\u001b[0;32m   1697\u001b[0m     \u001b[39m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     fast_tokenizer_file \u001b[39m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[1;32m-> 1699\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m   1700\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   1701\u001b[0m         TOKENIZER_CONFIG_FILE,\n\u001b[0;32m   1702\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1703\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   1704\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   1705\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1706\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   1707\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1708\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   1709\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m   1710\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   1711\u001b[0m         _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1712\u001b[0m         _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1713\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[0;32m   1714\u001b[0m     )\n\u001b[0;32m   1715\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   1716\u001b[0m     \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\transformers\\utils\\hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    406\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    410\u001b[0m         path_or_repo_id,\n\u001b[0;32m    411\u001b[0m         filename,\n\u001b[0;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    425\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\huggingface_hub\\file_download.py:1022\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m repo_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m REPO_TYPES:\n\u001b[0;32m   1016\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid repo type: \u001b[39m\u001b[39m{\u001b[39;00mrepo_type\u001b[39m}\u001b[39;00m\u001b[39m. Accepted repo types are:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(REPO_TYPES)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m storage_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m-> 1022\u001b[0m     cache_dir, repo_folder_name(repo_id\u001b[39m=\u001b[39;49mrepo_id, repo_type\u001b[39m=\u001b[39;49mrepo_type)\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m os\u001b[39m.\u001b[39mmakedirs(storage_folder, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1026\u001b[0m \u001b[39m# cross platform transcription of filename, to be used as a local file path.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:92\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[0;32m     88\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[0;32m     90\u001b[0m ):\n\u001b[0;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 92\u001b[0m         validate_repo_id(arg_value)\n\u001b[0;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:136\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRepo id must be a string, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(repo_id)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m     )\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    137\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[0;32m    142\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    143\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m     )\n",
            "\u001b[1;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/tokenizer/'. Use `repo_type` argument if needed."
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "\n",
        "use_cuda = False\n",
        "MODELPATH = '../model/bertmodel.pkl'\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"./models/tokenizer/\")\n",
        "\n",
        "model2 = BertModel()\n",
        "model2.load_state_dict(torch.load(MODELPATH, map_location=torch.device(device)))\n",
        "evaluate_one_text(model2, 'Bill Gates is the founder of Microsoft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An example is:\n",
            " A US Energy Department report Wednesday says the amount of oil available in the United States declined slightly last week by a bit more than one million barrels , to a total of nearly 314 million barrels .\n",
            "900\n"
          ]
        }
      ],
      "source": [
        "list_of_string_sentences = [[' '.join(sentence)] for sentence in sentences]\n",
        "list_of_string_sentences = [item for sublist in list_of_string_sentences for item in sublist]\n",
        "print('An example is:\\n', list_of_string_sentences[54])\n",
        "print(len(list_of_string_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_cuda = False\n",
        "MODELPATH = '../model/bertmodel.pkl'\n",
        "\n",
        "model2 = BertModel()\n",
        "model2.load_state_dict(torch.load(MODELPATH))\n",
        "model2.eval()\n",
        "evaluate_one_text(model2, 'Bill Gates is the founder of Microsoft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = [evaluate_one_text(model, sentenc) for sentenc in list_of_string_sentences[300]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['B-obj'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " ['I-per'],\n",
              " [],\n",
              " ['I-per']]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 26\n",
            "['I-per']\n",
            "In 2005 , Zambia qualified for debt relief under the Highly Indebted Poor Country Initiative , consisting of approximately USD 6 billion in debt relief .\n",
            "0\n",
            "1 13\n",
            "['I-per']\n",
            "Poverty remains a significant problem in Zambia , despite a stronger economy .\n",
            "1\n",
            "1 39\n",
            "['I-per']\n",
            "Zambia s dependency on copper makes it vulnerable to depressed commodity prices , but record high copper prices and a bumper maize crop in 2010 helped Zambia rebound quickly from the world economic slowdown that began in 2008 .\n",
            "2\n",
            "1 34\n",
            "['I-per']\n",
            "A high birth rate , relatively high HIV / AIDS burden , and market distorting agricultural policies have meant that Zambia s economic growth has not dramatically decreased the stubbornly high poverty rates .\n",
            "3\n",
            "1 15\n",
            "['I-per']\n",
            "Slovakia s roots can be traced to the 9th century state of Great Moravia .\n",
            "4\n",
            "1 20\n",
            "['I-per']\n",
            "Subsequently , the Slovaks became part of the Hungarian Kingdom , where they remained for the next 1 years .\n",
            "5\n",
            "1 50\n",
            "['I-per']\n",
            "Following the formation of the dual AustroHungarian monarchy in 1867 , language and education policies favoring the use of Hungarian ( Magyarization ) resulted in a strengthening of Slovak nationalism and a cultivation of cultural ties with the closely related Czechs , who were themselves ruled by the Austrians .\n",
            "6\n",
            "1 24\n",
            "['I-per']\n",
            "After the dissolution of the AustroHungarian Empire at the close of World War I , the Slovaks joined the Czechs to form Czechoslovakia .\n",
            "7\n",
            "1 18\n",
            "['I-per']\n",
            "Following the chaos of World War II , Czechoslovakia became a Communist nation within Sovietdominated Eastern Europe .\n",
            "8\n",
            "0 12\n",
            "[]\n",
            "Soviet influence collapsed in 1989 and Czechoslovakia once more became free .\n",
            "9\n",
            "1 14\n",
            "['B-obj']\n",
            "The Slovaks and the Czechs agreed to separate peacefully on 1 January 1993 .\n",
            "10\n",
            "1 21\n",
            "['I-per']\n",
            "Slovakia joined both NATO and the EU in the spring of 2004 and the euro area on 1 January 2009 .\n",
            "11\n",
            "1 14\n",
            "['I-per']\n",
            "The French Territory of the Afars and the Issas became Djibouti in 1977 .\n",
            "12\n",
            "1 17\n",
            "['I-per']\n",
            "Hassan Gouled APTIDON installed an authoritarian oneparty state and proceeded to serve as president until 1999 .\n",
            "13\n",
            "1 32\n",
            "['I-per']\n",
            "Unrest among the Afars minority during the 1990s led to a civil war that ended in 2001 following the conclusion of a peace accord between Afar rebels and the Issadominated government .\n",
            "14\n",
            "0 28\n",
            "[]\n",
            "In 1999 , Djibouti s first multiparty presidential elections resulted in the election of Ismail Omar GUELLEH ; he was reelected to a second term in 2005 .\n",
            "15\n",
            "1 30\n",
            "['I-per']\n",
            "Djibouti occupies a strategic geographic location at the mouth of the Red Sea and serves as an important transshipment location for goods entering and leaving the east African highlands .\n",
            "16\n",
            "1 28\n",
            "['I-per']\n",
            "The present leadership favors close ties to France , which maintains a significant military presence in the country , but also has strong ties with the US .\n",
            "17\n",
            "1 11\n",
            "['I-per']\n",
            "Djibouti hosts the only US military base in subSaharan Africa .\n",
            "18\n",
            "1 19\n",
            "['I-per']\n",
            "THE PIGEONS , terrified by the appearance of a Kite , called upon the Hawk to defend them .\n",
            "19\n",
            "1 5\n",
            "['I-per']\n",
            "He at once consented .\n",
            "20\n",
            "1 37\n",
            "['I-per']\n",
            "When they had admitted him into the cote , they found that he made more havoc and slew a larger number of them in one day than the Kite could pounce upon in a whole year .\n",
            "21\n",
            "1 10\n",
            "['I-per']\n",
            "Avoid a remedy that is worse than the disease .\n",
            "22\n",
            "1 29\n",
            "['I-per']\n",
            "THE members of the School Board in Doosnoswair being suspected of appointing female teachers for an improper consideration , the people elected a Board composed wholly of women .\n",
            "23\n",
            "0 20\n",
            "[]\n",
            "In a few years the scandal was at an end ; there were no female teachers in the Department .\n",
            "24\n",
            "1 47\n",
            "['I-per']\n",
            "A January 1994 Reuters News Service story on Manuel Oliveira s ice cream shop in Merida , Venezuela , reported on his 567 flavors , including onion , chili , beer , eggplant , smoked trout , spaghetti parmesan , chicken with rice , and spinach .\n",
            "25\n",
            "1 28\n",
            "['I-per']\n",
            "He said some flavors fail ; he once abandoned avocado ice cream , and tossed out 99 pounds of it , because it was nt smooth enough .\n",
            "26\n",
            "1 23\n",
            "['I-per']\n",
            "According to a news report , a certain private school in Victoria , BC , recently was faced with a unique problem .\n",
            "27\n",
            "1 20\n",
            "['I-per']\n",
            "A number of grade 12 girls were beginning to use lipstick and would put it on in the bathroom .\n",
            "28\n",
            "1 26\n",
            "['I-per']\n",
            "That was fine , but after they put on their lipstick they would press their lips to the mirror leaving dozens of little lip prints .\n",
            "29\n",
            "1 21\n",
            "['I-per']\n",
            "Every night , the maintenance man would remove them and the next day , The girls would put them back .\n",
            "30\n",
            "0 11\n",
            "[]\n",
            "Finally the principal decided that something had to be done .\n",
            "31\n",
            "1 17\n",
            "['I-per']\n",
            "She called all the girls to the bathroom and met them there with the maintenance man .\n",
            "32\n",
            "1 24\n",
            "['I-per']\n",
            "She explained that all these lip prints were causing a major problem for the custodian who had to clean the mirrors every night .\n",
            "33\n",
            "1 27\n",
            "['I-per']\n",
            "To demonstrate how difficult it had been to clean the mirrors , she asked the maintenance man to show the girls how much effort was required .\n",
            "34\n",
            "1 20\n",
            "['I-per']\n",
            "He took out a longhandled squeegee , dipped it in the toilet , and cleaned the mirror with it .\n",
            "35\n",
            "1 13\n",
            "['I-per']\n",
            "Since then , there have been no lip prints on the mirror .\n",
            "36\n",
            "1 9\n",
            "['I-per']\n",
            "There are teachers , and then there are educators \n",
            "37\n",
            "1 21\n",
            "['I-per']\n",
            "I am not a believer in sÂŽances , but I went to one just to see what they are like .\n",
            "38\n",
            "0 13\n",
            "[]\n",
            "The psychic was doing his thing and grinning from ear to ear .\n",
            "39\n",
            "1 25\n",
            "['I-per']\n",
            "I assumed his merriment was due to the fact that he was fooling a gullible public and gave him a poke in the nose .\n",
            "40\n",
            "0 6\n",
            "[]\n",
            "You can probably guess the rest \n",
            "41\n",
            "1 8\n",
            "['I-per']\n",
            "I was arrested for striking a happy medium \n",
            "42\n",
            "1 19\n",
            "['I-per']\n",
            "Ethiopia Saturday released 32 supporters of the political opposition who had been detained since postelection violence in 2005 .\n",
            "43\n",
            "1 13\n",
            "['I-per']\n",
            "Their release comes after Ethiopia pardoned another 38 opposition members last month .\n",
            "44\n",
            "1 14\n",
            "['I-per']\n",
            "That group had received life sentences in court the week before their pardons .\n",
            "45\n",
            "1 15\n",
            "['I-per']\n",
            "None of the 32 freed Saturday had been charged in court with any crimes .\n",
            "46\n",
            "1 14\n",
            "['I-per']\n",
            "All had been rounded up after protests over the 2005 elections turned violent .\n",
            "47\n",
            "0 11\n",
            "[]\n",
            "The opposition made its largest gains ever in those elections .\n",
            "48\n",
            "1 16\n",
            "['I-per']\n",
            "Opposition groups claimed the elections were rigged to keep Prime Minister Meles Zenawi in power .\n",
            "49\n",
            "1 13\n",
            "['I-per']\n",
            "Ethiopian security forces killed at least 193 people while stopping the protests .\n",
            "50\n",
            "1 21\n",
            "['I-per']\n",
            "World oil prices hit a new record in Wednesday s trading , hitting $ 9929 a barrel before easing downward .\n",
            "51\n",
            "0 16\n",
            "[]\n",
            "That is 67 cents above the previous record , which was set on November 7 .\n",
            "52\n",
            "1 29\n",
            "['I-per']\n",
            "Traders say the soaring prices stem from the declining value of the US dollar and worries about the supply of oil in the Northern Hemisphere as winter approaches .\n",
            "53\n",
            "1 38\n",
            "['I-per']\n",
            "A US Energy Department report Wednesday says the amount of oil available in the United States declined slightly last week by a bit more than one million barrels , to a total of nearly 314 million barrels .\n",
            "54\n",
            "1 23\n",
            "['I-per']\n",
            "French Foreign Minister Philippe DousteBlazy is in Moscow for talks with top Russian officials expected to focus on Iran s nuclear program .\n",
            "55\n",
            "1 38\n",
            "['I-per']\n",
            "France , along with Britain and Germany , called for an emergency session of the International Atomic Energy Agency on February 2 , to hear the European case for referring Iran to the United Nations Security Council .\n",
            "56\n",
            "1 20\n",
            "['I-per']\n",
            "The Security Council can impose sanctions , if it finds Iran has violated international treaties with its nuclear program .\n",
            "57\n",
            "0 21\n",
            "[]\n",
            "The call for the IAEA . session came after Tehran broke a twoyear moratorium on nuclear research earlier this month .\n",
            "58\n",
            "1 15\n",
            "['I-per']\n",
            "The United States has accused Iran of using its research to develop nuclear weapons .\n",
            "59\n",
            "1 8\n",
            "['I-per']\n",
            "Tehran insists its nuclear intentions are peaceful .\n",
            "60\n",
            "1 15\n",
            "['I-per']\n",
            "China Thursday called for \" restraint and patience \" to resolve the nuclear crisis .\n",
            "61\n",
            "1 26\n",
            "['I-per']\n",
            "Residents of the US state of Florida are stocking up on gasoline , water and other supplies as Tropical Storm Katrina moves toward the area .\n",
            "62\n",
            "1 25\n",
            "['I-per']\n",
            "Forecasters expect the storm to bring heavy rainfall and possible flooding to much of southern and central Florida when it makes landfall later Thursday .\n",
            "63\n",
            "1 28\n",
            "['I-per']\n",
            "Hurricane and tropical storm warnings have been posted for many areas as the storm moves westward , away from the Bahamas and toward Florida s southeast coast .\n",
            "64\n",
            "1 20\n",
            "['I-per']\n",
            "The US National Hurricane Center says Katrina may gain strength and become a category one hurricane before reaching land .\n",
            "65\n",
            "1 15\n",
            "['I-per']\n",
            "At last report , the storm was packing winds of 85 kilometers per hour .\n",
            "66\n",
            "1 12\n",
            "['I-per']\n",
            "A tropical storm warning remains in effect for the northwest Bahamas .\n",
            "67\n",
            "0 17\n",
            "[]\n",
            "Parts of Florida are still recovering from the four hurricanes that hit the state last year .\n",
            "68\n",
            "1 34\n",
            "['I-per']\n",
            "The US military in Iraq says American warplanes have bombed two bridges in western alAnbar province , to stop insurgents from using them to move fighters and equipment to other cities for attacks .\n",
            "69\n",
            "1 21\n",
            "['I-per']\n",
            "The air strikes Tuesday near the Syrian border did not destroy the Euphrates River bridges , but made them inoperable .\n",
            "70\n",
            "1 5\n",
            "['I-per']\n",
            "No casualties were reported .\n",
            "71\n",
            "1 17\n",
            "['I-per']\n",
            "Coalition troops also raided a nearby safehouse , killing two foreign fighters and detaining three others .\n",
            "72\n",
            "1 6\n",
            "['I-per']\n",
            "The building was later destroyed .\n",
            "73\n",
            "1 24\n",
            "['I-per']\n",
            "Elsewhere , in the southern Shiite holy city of Najaf , US forces handed over military control of the city to Iraqi forces .\n",
            "74\n",
            "0 24\n",
            "[]\n",
            "In other developments , the US military reports two American soldiers were killed and two wounded Tuesday in a bomb blast in Baghdad .\n",
            "75\n",
            "1 12\n",
            "['I-per']\n",
            "Two more soldiers were killed Monday in Tal Afar and Ramadi .\n",
            "76\n",
            "1 31\n",
            "['I-per']\n",
            "Britain says finance ministers from the Group of Seven industrial nations have expressed a willingness to cancel up to 100 percent of the debt of the world s poorest nations .\n",
            "77\n",
            "1 29\n",
            "['I-per']\n",
            "Britain s Treasury chief Gordon Brown said at the close of the G7 summit in London Saturday , that debt relief would be decided on a casebycase basis .\n",
            "78\n",
            "0 21\n",
            "[]\n",
            "Britain had also pushed for the G7 to support London s plan to double international aid to the developing world .\n",
            "79\n",
            "1 8\n",
            "['I-per']\n",
            "But the United State rejected that proposal .\n",
            "80\n",
            "1 19\n",
            "['I-per']\n",
            "US Treasury Undersecretary John Taylor told BBC radio the plan did not fit into the US budget process .\n",
            "81\n",
            "1 30\n",
            "['I-per']\n",
            "Britain s International Development Secretary Hilary Benn promised to push ahead with the plan , saying a solution will be found by 2006 with or without the United States .\n",
            "82\n",
            "1 27\n",
            "['I-per']\n",
            "US Undersecretary of State Nicholas Burns has expressed doubt that Washington and New Delhi will finalize a nuclear deal before President Bush visits India next week .\n",
            "83\n",
            "0 17\n",
            "[]\n",
            "Burns made the comment following talks with Indian Foreign Secretary Shyam Saran in New Delhi Wednesday .\n",
            "84\n",
            "1 22\n",
            "['I-per']\n",
            "He said both sides want to complete the negotiations , but added there are differences that need to be worked out .\n",
            "85\n",
            "1 5\n",
            "['I-per']\n",
            "He did not elaborate .\n",
            "86\n",
            "0 35\n",
            "[]\n",
            "Under the deal , India would gain access to longdenied US nuclear technology in exchange for including some of its reactors on a list of civilian facilities that would be subject to international inspections .\n",
            "87\n",
            "1 10\n",
            "['I-per']\n",
            "Burns and Saran are to continue talks on Friday .\n",
            "88\n",
            "1 7\n",
            "['I-per']\n",
            "Some US legislators oppose the deal .\n",
            "89\n",
            "1 10\n",
            "['I-per']\n",
            "They say it could undermine the Nuclear NonProliferation Treaty .\n",
            "90\n",
            "1 7\n",
            "['I-per']\n",
            "India has not signed the treaty .\n",
            "91\n",
            "1 27\n",
            "['I-per']\n",
            "A top UN official says indirect talks between the Ugandan government and northern rebels have provided the best chance for peace in 18 years of conflict .\n",
            "92\n",
            "1 19\n",
            "['I-per']\n",
            "UN Emergency Relief Coordinator Jan Egeland praised the Ugandan government Tuesday for its renewed efforts to seek dialogue .\n",
            "93\n",
            "0 35\n",
            "[]\n",
            "Mr Egeland says the conflict has forced up to 90 percent of the population in some areas of northern Uganda from their homes , adding that hundreds of thousands of lives are at stake .\n",
            "94\n",
            "1 23\n",
            "['I-per']\n",
            "Rebels from the Lord s Resistance Army are notorious for attacking civilians and kidnapping children for use as soldiers or sex slaves .\n",
            "95\n",
            "1 22\n",
            "['I-per']\n",
            "Over the last few weeks , the rebels and the Ugandan government declared a temporary ceasefire and held talks through mediators .\n",
            "96\n",
            "1 22\n",
            "['I-per']\n",
            "The government says it is extending the truce for another week in the hopes of starting formal peace talks by then .\n",
            "97\n",
            "0 27\n",
            "[]\n",
            "An Ethiopian judge has ordered a group of 131 detained opposition leaders , journalists and others to remain in custody after most boycotted a bail hearing .\n",
            "98\n",
            "1 26\n",
            "['I-per']\n",
            "Most lawyers for the group boycotted Wednesday s Ethiopian High Court hearing , saying prison authorities have not allowed them to meet with their clients .\n",
            "99\n",
            "1 20\n",
            "['I-per']\n",
            "The detained have been charged with treason and genocide for their alleged involvement in election protests that turned violent .\n",
            "100\n",
            "0 13\n",
            "[]\n",
            "The judge says he will rule on the bail requests next week .\n",
            "101\n",
            "1 16\n",
            "['I-per']\n",
            "The accused include five journalists with the Voice of America s Amhariclanguage service in Washington .\n",
            "102\n",
            "1 13\n",
            "['I-per']\n",
            "They were charged in absentia with plotting to overthrow the Ethiopian government .\n",
            "103\n",
            "1 29\n",
            "['I-per']\n",
            "Ethiopia s information minister told VOA English to Africa Service that the journalists have incited violence through their reports and he accused them of working with the opposition .\n",
            "104\n",
            "1 17\n",
            "['I-per']\n",
            "VOA officials reject the charges , and say they are an attempt to intimidate VOA journalists .\n",
            "105\n",
            "1 28\n",
            "['I-per']\n",
            "Vice President Dick Cheney says a premature withdrawal of US forces from Iraq would be a victory for the terrorists and a blow to American national security .\n",
            "106\n",
            "1 38\n",
            "['I-per']\n",
            "In a speech in Washington Monday , Mr Cheney responded to critics , including Democratic Congressman John Murtha , who say the US military s presence in Iraq has increased terrorism and instability in the Middle East .\n",
            "107\n",
            "1 29\n",
            "['I-per']\n",
            "Congressman Murtha s call last week for US troops to get out of Iraq sparked intense debate and drew stinging criticism from Republican legislators and White House officials .\n",
            "108\n",
            "0 15\n",
            "[]\n",
            "Mr Cheney Monday called Mr Murtha \" a good man and a patriot . \"\n",
            "109\n",
            "1 34\n",
            "['I-per']\n",
            "But the vice president stood by his remarks that it is \" dishonest and reprehensible \" for some US senators to say President Bush purposely misled the American people into the Iraq war .\n",
            "110\n",
            "1 34\n",
            "['I-per']\n",
            "Poland s foreign minister says the European Union ( EU ) will not start entry talks with Croatia unless that country hands over a top fugitive war crimes suspect to The Hague tribunal .\n",
            "111\n",
            "0 15\n",
            "[]\n",
            "Adam Rotfeld told reporters a March 17 date has been set for the talks .\n",
            "112\n",
            "1 21\n",
            "['I-per']\n",
            "But he warned that unless Croatia surrenders General Ante Gotovina , the European Union will simply not open the discussions .\n",
            "113\n",
            "1 30\n",
            "['I-per']\n",
            "The Polish minister , whose country gained EU membership last May , made his comments after talks in Warsaw with the tribunal s chief prosecutor , Carla del Ponte .\n",
            "114\n",
            "1 23\n",
            "['I-per']\n",
            "The prosecutor confirmed that she had sent a letter to the European Union , criticizing Croatia for failing to arrest General Gotovina .\n",
            "115\n",
            "1 28\n",
            "['I-per']\n",
            "The Hague court indicted the general for his role in the deaths of civilians during a 1995 Croatian army sweep through a Serbheld area of the country .\n",
            "116\n",
            "0 19\n",
            "[]\n",
            "Turkish authorities say a suicide bomber was behind Tuesday s blast that killed six other people in Ankara .\n",
            "117\n",
            "1 23\n",
            "['I-per']\n",
            "Ankara Governor Kemal Onal said Wednesday the bomber had a police record and used explosives similar to those used by Kurdish militants .\n",
            "118\n",
            "1 11\n",
            "['I-per']\n",
            "There has been no claim of responsibility for the blast .\n",
            "119\n",
            "1 15\n",
            "['I-per']\n",
            "Turkish Prime Minister Recep Tayyip Erdogan described the bombing as a ruthless terrorist attack .\n",
            "120\n",
            "0 24\n",
            "[]\n",
            "The Pakistani embassy says eight Pakistanis were among the more than 90 people wounded in the blast in a commercial district , Ulus .\n",
            "121\n",
            "1 12\n",
            "['I-per']\n",
            "The Pakistanis were in Ankara for an international defense industry fair .\n",
            "122\n",
            "1 22\n",
            "['I-per']\n",
            "The rebel Kurdistan Workers Party ( PKK ) has been fighting for autonomy in Turkey s mainly Kurdish southeast since 1984 .\n",
            "123\n",
            "1 27\n",
            "['I-per']\n",
            "The European Union has decided to tighten sanctions on Burma after the military government failed to meet EU demands for progress on democracy and human rights .\n",
            "124\n",
            "1 27\n",
            "['I-per']\n",
            "EU foreign ministers meeting in Luxembourg Monday voted to widen a visa blacklist on members of Burma s military junta and place stricter controls on investment .\n",
            "125\n",
            "1 41\n",
            "['I-per']\n",
            "EU officials had threatened the move ahead of the AsiaEurope summit in Hanoi last week , after Burma ignored demands for the the release of democracy leader Aung San Suu Kyi and the lifting of restrictions on her prodemocracy party .\n",
            "126\n",
            "1 16\n",
            "['I-per']\n",
            "Sunday Burma s stateowned media said Western nations can not use sanctions to impose democracy .\n",
            "127\n",
            "1 25\n",
            "['I-per']\n",
            "US officials say a group of US congressmen was denied entry into Venezuela Monday after landing at the country s main airport near Caracas .\n",
            "128\n",
            "1 18\n",
            "['I-per']\n",
            "The delegation was led by Illinois Republican Henry Hyde , chairman of the House International Relations Committee .\n",
            "129\n",
            "1 11\n",
            "['I-per']\n",
            "They had arrived in the country for a scheduled visit .\n",
            "130\n",
            "1 33\n",
            "['I-per']\n",
            "A US embassy official said the visit was canceled after Venezuelan officials kept the delegation s military jet on the tarmac for a least an hour without allowing the lawmakers to disembark .\n",
            "131\n",
            "0 19\n",
            "[]\n",
            "Caracas airport official Jose Cabello denies this , saying the group made no attempt to contact Venezuelan authorities .\n",
            "132\n",
            "1 20\n",
            "['I-per']\n",
            "Relations between Washington and Caracas have been strained ever since populist President Hugo Chavez came to office in 1999 .\n",
            "133\n",
            "1 14\n",
            "['I-per']\n",
            "Mr Chavez has repeatedly accused the Bush administration of planning to invade Venezuela .\n",
            "134\n",
            "0 24\n",
            "[]\n",
            "Washington denies any such plans , and warns that Mr Chavez is becoming an authoritarian threat to Venezuela s democracy and regional stability .\n",
            "135\n",
            "1 27\n",
            "['I-per']\n",
            "Early results from Haiti s presidential election indicate frontrunner candidate Rene Preval has a commanding lead , and may be able to avoid a runoff election .\n",
            "136\n",
            "1 22\n",
            "['I-per']\n",
            "Officials say Preval , a former president , has won about 61 percent of the votes counted from Tuesday s election .\n",
            "137\n",
            "1 15\n",
            "['I-per']\n",
            "Another former president , Leslie Manigat , is a distant second with 13 percent .\n",
            "138\n",
            "1 21\n",
            "['I-per']\n",
            "If the trend continues , Preval would have a clear majority of votes and avoid a runoff election next month .\n",
            "139\n",
            "1 25\n",
            "['I-per']\n",
            "Vote counting is said to be proceeding slowly as ballots trickle in to the capital , PortauPrince , by helicopter , truck and mule .\n",
            "140\n",
            "1 27\n",
            "['I-per']\n",
            "Brazil s President Luiz Inacio Lula da Silva says Brazilian peacekeeping forces will remain in Haiti until a new government is formed and can maintain security .\n",
            "141\n",
            "1 12\n",
            "['I-per']\n",
            "Brazil is the leader of the UN stabilization force in Haiti .\n",
            "142\n",
            "0 26\n",
            "[]\n",
            "US and Iraqi government forces have captured scores of suspected insurgents and seized an enormous stockpile of weapons and explosives during antiinsurgent operations in Iraq .\n",
            "143\n",
            "1 23\n",
            "['I-per']\n",
            "The US military says 81 suspected rebels were rounded up Thursday in raids around Youssifiyeh , south of the capital , Baghdad .\n",
            "144\n",
            "1 21\n",
            "['I-per']\n",
            "Iraqi officials say Abu Saeed , a top lieutenant of wanted terrorist Abu Musab alZarqawi , was captured in Mosul .\n",
            "145\n",
            "1 27\n",
            "['I-per']\n",
            "Military officials also say US and Iraqi troops uncovered what they called the largest cache of weapons found so far , in a mosque in Fallujah .\n",
            "146\n",
            "0 23\n",
            "[]\n",
            "The discovery came as Iraqi troops searching for suspected terrorist hideouts in Fallujah uncovered what appeared to be a chemical bomb factory .\n",
            "147\n",
            "1 20\n",
            "['I-per']\n",
            "Iraqi officials say the laboratory may have been used to make toxic substances and contained pamphlets on manufacturing anthrax .\n",
            "148\n",
            "1 36\n",
            "['I-per']\n",
            "The head of the Palestinian mission in Peru has told protesters in Lima that the kidnapping of a Peruvian photographer in the Gaza Strip is damaging the \" just fight \" of the Palestinian people .\n",
            "149\n",
            "1 13\n",
            "['I-per']\n",
            "Walid Abdel Rahim spoke to protesters on Friday outside the Palestinian mission .\n",
            "150\n",
            "1 8\n",
            "['I-per']\n",
            "He condemned the kidnapping of Jaime Razuri .\n",
            "151\n",
            "1 8\n",
            "['I-per']\n",
            "The protesters called for Razuri s release .\n",
            "152\n",
            "1 10\n",
            "['I-per']\n",
            "The crowd included Razuri s family and international journalists .\n",
            "153\n",
            "1 10\n",
            "['I-per']\n",
            "Razuri is an employee of the French news agency .\n",
            "154\n",
            "0 15\n",
            "[]\n",
            "Gunmen seized him on Monday outside the news agency s offices in Gaza City .\n",
            "155\n",
            "1 9\n",
            "['I-per']\n",
            "No group has claimed responsibility for the kidnapping .\n",
            "156\n",
            "1 16\n",
            "['I-per']\n",
            "Kidnappings are frequent in the Gaza Strip , but hostages are usually released within hours .\n",
            "157\n",
            "0 23\n",
            "[]\n",
            "Chinese authorities have banned the use of foreign words and phrases Ã especially English Ã in Chinese newspapers , books and websites .\n",
            "158\n",
            "1 24\n",
            "['I-per']\n",
            "The ban , reported Wednesday , was issued by the General Administration of Press and Publication , the governing body for written publications .\n",
            "159\n",
            "1 31\n",
            "['I-per']\n",
            "It says the increasing use of English and halfEnglish phrases is damaging the purity of the Chinese language and disrupting the nation s \" harmonious and healthy cultural environment . \"\n",
            "160\n",
            "0 26\n",
            "[]\n",
            "The ruling body leaves some room for English words and abbreviations to be used if they are immediately followed by a Chinese translation or explanation .\n",
            "161\n",
            "1 13\n",
            "['I-per']\n",
            "It says translations should be consistent with basic translation principles and practices .\n",
            "162\n",
            "1 17\n",
            "['I-per']\n",
            "The announcement includes a warning that violations will be punished as provided for by the law .\n",
            "163\n",
            "1 33\n",
            "['I-per']\n",
            "Israeli Defense Minister Ehud Barak has canceled a visit to Paris where he was to take part in an international military exhibition , and meet with the French defense and foreign ministers .\n",
            "164\n",
            "1 30\n",
            "['I-per']\n",
            "Israel s defense ministry said Sunday that Barak has decided to remain in Israel until a panel of experts is formed to investigate the raid on a Gazabound flotilla .\n",
            "165\n",
            "1 35\n",
            "['I-per']\n",
            "Earlier this month , Israel drew international criticism after its soldiers killed nine proPalestinian activists who were part of a flotilla that was trying to break a blockade and deliver aid directly to Gaza .\n",
            "166\n",
            "1 26\n",
            "['I-per']\n",
            "French activists said they plan on filing a lawsuit against Barak in France , as well as with the International Criminal Court in the Netherlands .\n",
            "167\n",
            "0 35\n",
            "[]\n",
            "Barak told Israel s parliament last week that an internal inquiry will aim to establish whether Israel s raid on the ship , and its Gaza blockade , are in keeping with international law .\n",
            "168\n",
            "1 26\n",
            "['I-per']\n",
            "A surgeon in Miami used his skill in transplanting organs to save the life of a woman who had been told her cancer was inoperable .\n",
            "169\n",
            "1 16\n",
            "['I-per']\n",
            "In this breakthrough surgery , doctors narrowed the scope of what is now considered inoperable .\n",
            "170\n",
            "0 6\n",
            "[]\n",
            "VOA s Carol Pearson reports .\n",
            "171\n",
            "1 23\n",
            "['I-per']\n",
            "A suicide bomber blew himself up near a NATO base in eastern Afghanistan Tuesday , killing 10 civilians and wounding 14 others .\n",
            "172\n",
            "1 35\n",
            "['I-per']\n",
            "An Afghan official , provincial governor Arsala Jamal , says the bomber set off his explosives in a crowd of laborers waiting to get inside a NATO military base in the city of Khost .\n",
            "173\n",
            "1 8\n",
            "['I-per']\n",
            "There were no NATO or US casualities .\n",
            "174\n",
            "1 24\n",
            "['I-per']\n",
            "In a separate incident in the south , suspected Taleban militants ambushed a police patrol in Kandahar , killing at least eight policemen .\n",
            "175\n",
            "1 18\n",
            "['I-per']\n",
            "Attacks by Taleban militants against NATO , US and Afghan forces increased dramatically in Afghanistan last year .\n",
            "176\n",
            "1 28\n",
            "['I-per']\n",
            "US and Afghan officials have warned they expect an increase in Taleban attacks in the coming months in what has been called a \" spring offensive . \"\n",
            "177\n",
            "1 18\n",
            "['I-per']\n",
            "Palestinian officials have confirmed that elections to replace president Yasser Arafat will be held on January 9 .\n",
            "178\n",
            "1 22\n",
            "['I-per']\n",
            "Caretaker President Rawhi Fattouh said Sunday the nominating period for candidates will begin November 20 , and run for 12 days .\n",
            "179\n",
            "0 17\n",
            "[]\n",
            "The announcement of the vote comes three days after Mr Arafat died in a Paris hospital .\n",
            "180\n",
            "1 7\n",
            "['I-per']\n",
            "He did not appoint a successor .\n",
            "181\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(predictions)):\n",
        "  if len(predictions[i]) != len(list_of_string_sentences[i].split()):\n",
        "    print(len(predictions[i]), len(list_of_string_sentences[i].split()))\n",
        "    print(predictions[i])\n",
        "    print(list_of_string_sentences[i])\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_cuda = False\n",
        "MODELPATH = './model/bert_NER_10_24.pt'\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = torch.load(MODELPATH, map_location=torch.device(device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "e7db67da143e433083230dcdf06917ca",
            "c6e934b562384fca90bfdefd60a905c9",
            "2c7d8aa01d7e45fe81481c0e2e239999",
            "429648c676b2414a9483bbd1981ca37f",
            "af31604290854d35a0a44e5304f62dbd",
            "573256320153457e8defdbf911bd449d",
            "08e27a9f8ce841508b2281e3d0d8e8f0",
            "3f19c40fb05c41b5922229b649ee44ea",
            "b340c98e3863417184598a393311d312",
            "a269d9a957164b699772e8b943c329fe",
            "6e2b854ca48a4acdbd89de8ca4bda2cd"
          ]
        },
        "id": "a9SiZreop2H7",
        "outputId": "68e14913-50c2-47a1-b4be-c1d9a05c3fff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32me:\\Egyetem\\Msc1\\szoveg_es_web\\bertner_w.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m BATCH_SIZE \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m model \u001b[39m=\u001b[39m BertModel()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m train_loop(model, df_train, df_val)\n",
            "\u001b[1;32me:\\Egyetem\\Msc1\\szoveg_es_web\\bertner_w.ipynb Cell 12\u001b[0m in \u001b[0;36mBertModel.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39msuper\u001b[39m(BertModel, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Egyetem/Msc1/szoveg_es_web/bertner_w.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert \u001b[39m=\u001b[39m BertForTokenClassification\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39mbert-base-cased\u001b[39;49m\u001b[39m'\u001b[39;49m, num_labels\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(unique_labels))\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\transformers\\modeling_utils.py:2089\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   2076\u001b[0m     cached_file_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m   2077\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m   2078\u001b[0m         force_download\u001b[39m=\u001b[39mforce_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2087\u001b[0m         _commit_hash\u001b[39m=\u001b[39mcommit_hash,\n\u001b[0;32m   2088\u001b[0m     )\n\u001b[1;32m-> 2089\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcached_file_kwargs)\n\u001b[0;32m   2091\u001b[0m     \u001b[39m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   2092\u001b[0m     \u001b[39m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m     \u001b[39mif\u001b[39;00m resolved_archive_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m filename \u001b[39m==\u001b[39m SAFE_WEIGHTS_NAME:\n\u001b[0;32m   2094\u001b[0m         \u001b[39m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\transformers\\utils\\hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    406\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    410\u001b[0m         path_or_repo_id,\n\u001b[0;32m    411\u001b[0m         filename,\n\u001b[0;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    425\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\huggingface_hub\\file_download.py:1226\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1223\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[0;32m   1224\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1226\u001b[0m     http_get(\n\u001b[0;32m   1227\u001b[0m         url_to_download,\n\u001b[0;32m   1228\u001b[0m         temp_file,\n\u001b[0;32m   1229\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1230\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m   1231\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1232\u001b[0m     )\n\u001b[0;32m   1234\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, blob_path)\n\u001b[0;32m   1235\u001b[0m os\u001b[39m.\u001b[39mreplace(temp_file\u001b[39m.\u001b[39mname, blob_path)\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\huggingface_hub\\file_download.py:490\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001b[0m\n\u001b[0;32m    481\u001b[0m total \u001b[39m=\u001b[39m resume_size \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(content_length) \u001b[39mif\u001b[39;00m content_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    482\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m    483\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    484\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[0;32m    489\u001b[0m )\n\u001b[1;32m--> 490\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[0;32m    491\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    492\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\urllib3\\response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[1;32m--> 627\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    629\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    630\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\urllib3\\response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    563\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    565\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 566\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\site-packages\\urllib3\\response.py:532\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    531\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32mc:\\Users\\meste\\anaconda3\\envs\\nlp_bert\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def train_loop(model, df_train, df_val):\n",
        "\n",
        "    train_dataset = DataSequence(df_train)\n",
        "    val_dataset = DataSequence(df_val)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    best_acc = 0\n",
        "    best_loss = 1000\n",
        "\n",
        "    for epoch_num in range(EPOCHS):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss, logits = model(input_id, mask, train_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][train_label[i] != -100]\n",
        "              label_clean = train_label[i][train_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_train += acc\n",
        "              total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            model.eval()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        for val_data, val_label in val_dataloader:\n",
        "\n",
        "            val_label = val_label.to(device)\n",
        "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, val_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][val_label[i] != -100]\n",
        "              label_clean = val_label[i][val_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_val += acc\n",
        "              total_loss_val += loss.item()\n",
        "\n",
        "        val_accuracy = total_acc_val / len(df_val)\n",
        "        val_loss = total_loss_val / len(df_val)\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n",
        "\n",
        "LEARNING_RATE = 5e-3\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "model = BertModel()\n",
        "train_loop(model, df_train, df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgtX9bRBqB7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6dv0ahrqf4Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('nlp_bert')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "37ff7d383120de78e4cb1d778d7faf790bc36f3bc2b9c0df490a9411413866a9"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08e27a9f8ce841508b2281e3d0d8e8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c7d8aa01d7e45fe81481c0e2e239999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f19c40fb05c41b5922229b649ee44ea",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b340c98e3863417184598a393311d312",
            "value": 435779157
          }
        },
        "3f19c40fb05c41b5922229b649ee44ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429648c676b2414a9483bbd1981ca37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a269d9a957164b699772e8b943c329fe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6e2b854ca48a4acdbd89de8ca4bda2cd",
            "value": " 436M/436M [00:07&lt;00:00, 58.4MB/s]"
          }
        },
        "573256320153457e8defdbf911bd449d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e2b854ca48a4acdbd89de8ca4bda2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a269d9a957164b699772e8b943c329fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af31604290854d35a0a44e5304f62dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b340c98e3863417184598a393311d312": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6e934b562384fca90bfdefd60a905c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573256320153457e8defdbf911bd449d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_08e27a9f8ce841508b2281e3d0d8e8f0",
            "value": "Downloading: 100%"
          }
        },
        "e7db67da143e433083230dcdf06917ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6e934b562384fca90bfdefd60a905c9",
              "IPY_MODEL_2c7d8aa01d7e45fe81481c0e2e239999",
              "IPY_MODEL_429648c676b2414a9483bbd1981ca37f"
            ],
            "layout": "IPY_MODEL_af31604290854d35a0a44e5304f62dbd"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
